Swarm mode is the orchestration feature built into Docker. It's a production-grade orchestrator which uses the familiar Docker Compose format to model applications.
We'll create a Swarm cluster for this section and deploy some apps to get a feel for running containers in production.
If you plan on using a different orchestrator - like K8s or Nomad - the patterns are the same, so what you learn here will still apply.

For simulating VMs on local machine, we can use Vagrant to setup multiple VMs on a single machine.
We need to have docker installed and they need to be joined into a cluster.

Swarm has 2 types of nodes:
    Manager
    Worker

We need to initialize the Swarm on the node that's going to be our manager node.

With Docker, we get 2 modes:
    1. Standalone Mode
    2. Swarm mode - Using which we can connect into the cluster and have orchestration capabilities

Command to initialize swarm on Manager node:
=============
docker swarm init
=============
As output, we will get a join command that we need to run on worker machines to connect it to the manager machine.
For PROD, it'd be ideally 3 manager nodes. For joining multiple manager nodes, we can get the token using this command:

Command to join Managers(For HA)
===============================
docker swarm join-token manager
===============================

Command to join Workers
=================================
docker swarm join-token worker
=================================

When we have multiple VMs running on same machine, each of them have their own IP addresses. 
In such cases, its ideal to specify the IP addresss explicitly that the manager should use to join the worker with it.

We can do it using --advertise-addr [IP address] to the join command. So, it looks like this:
==========================
docker swarm join [join-token] --advertise-addr [IP Address]
==========================

We can go individual nodes and then join them to the swarm,

Because Docker Swarm is an abstraction around the containers, it runs the applications as "services". It decides on which worker should it run the container etc.

If we want to deploy a basic whoamI application, we can give it as:
======================
docker service create --name whoami -p 8080:80 docker4dotnet/whoami
======================
The above mentioned is equivalent to docker run command

When we execute it, we get the output as tasks. This terminology is different as compared to standalone mode
Task == Container.

Service commands are only applicable on Swarm mode

How to know which node is running my service?
==============
docker service ps whoami
==============
We can see this is running on Manager node. It could run on either of the nodes. The manager makes that decision to run the service on whichever node has the most AVAILABLE RESOURCES(CPU/Memory etc.)

IMP
When we publish any port, all the services listen to that port.
Any traffic coming onto any server in the cluster, will be redirected to container that's listening on that port.
This helps with load balancing as well. If we try to access the IP of server that's not running any container, it'll redirect us to the container that's listening on the port that's being supplied into.

So, even if we browse to worker mode, we will see response coming back to us from container that's currently running on manager node.

Benefits of using service:
Unlike running in standalone mode, when we do docker run, we get 1 container.
With service, we can create replica(multiple copies) of it.

Command to replicate existing service running on swarm:
============
docker service update --replicas 10 whoami
============
We can see that the containers are now spread evenly. Some are running on Linux worker, some on windows worker and some even on manager

If we get the URL of the windows worker and set it to environment variable and then execute curl to the same URL, we would see it is being served by different instances everytime we request it.
SO, the REQUESTS ARE NICELY LOAD BALANCED.

For checking logs, we do not need to connect to individual containers, instead we could execute service logs and it will scoop out logs coming out of each container.
========
docker service logs whoami
========

For removing service:
=========
docker service rm whoami
=========
This will remove all tasks.

More information here:

Deploy a basic web app:

docker service create --name whoami -p 8080:80 docker4dotnet/whoami

docker service ps whoami

docker node inspect worker -f '{{.Status.Addr}}'

docker node inspect manager -f '{{.Status.Addr}}'
There's a single container running the service, but you can browse to port 8080 on any node and the traffic gets routed to the container.

Scale up and more containers will be created. Publishing a port in Swarm mode uses the ingress network, so incoming requests get load-balanced between containers.

Update the service to scale up:
===================
docker service update --replicas 10 whoami

docker service ps whoami

url="$(docker node inspect winworker -f '{{.Status.Addr}}'):8080"

echo $url

curl $url
===================
This is a multi-architecture .NET Core image, so it can run on Windows or Linux. Repeat the curl command to see different OS responses.

Check the logs and clear up:
==============
docker service logs whoami

docker service rm whoami

docker ps
==============
Services are first-class citizens which you administer on the manager node. Swarm mode enables extra features in the Docker CLI, but you can only use them on the manager - typically you'd set up a remote connection.

Typically, we won't be using service commands directly. Instead, we would be modelling our application using docker compose and format it to support swarm mode.
